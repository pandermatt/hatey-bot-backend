{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from config import config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         example_no    is_abuse.1    is_abuse.0   is_abuse.-1   is_abuse.-2  \\\ncount  12768.000000  12768.000000  12768.000000  12768.000000  12768.000000   \nmean    6383.500000      0.788534      0.052553      0.063675      0.073152   \nstd     3685.948453      0.408364      0.223149      0.244182      0.260395   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%     3191.750000      1.000000      0.000000      0.000000      0.000000   \n50%     6383.500000      1.000000      0.000000      0.000000      0.000000   \n75%     9575.250000      1.000000      0.000000      0.000000      0.000000   \nmax    12767.000000      1.000000      1.000000      1.000000      1.000000   \n\n        is_abuse.-3  type.ableism  type.homophobic  type.intellectual  \\\ncount  12768.000000  12768.000000     12768.000000       12768.000000   \nmean       0.022086      0.001096         0.006501           0.026159   \nstd        0.146971      0.033096         0.080367           0.159615   \nmin        0.000000      0.000000         0.000000           0.000000   \n25%        0.000000      0.000000         0.000000           0.000000   \n50%        0.000000      0.000000         0.000000           0.000000   \n75%        0.000000      0.000000         0.000000           0.000000   \nmax        1.000000      1.000000         1.000000           1.000000   \n\n        type.racist   type.sexist  type.sex_harassment  type.transphobic  \\\ncount  12768.000000  12768.000000         12768.000000      12768.000000   \nmean       0.002115      0.022321             0.044643          0.000313   \nstd        0.045939      0.147733             0.206527          0.017698   \nmin        0.000000      0.000000             0.000000          0.000000   \n25%        0.000000      0.000000             0.000000          0.000000   \n50%        0.000000      0.000000             0.000000          0.000000   \n75%        0.000000      0.000000             0.000000          0.000000   \nmax        1.000000      1.000000             1.000000          1.000000   \n\n       target.generalised  target.individual  target.system  \\\ncount        12768.000000       12768.000000   12768.000000   \nmean             0.003603           0.007597       0.149593   \nstd              0.059917           0.086833       0.356686   \nmin              0.000000           0.000000       0.000000   \n25%              0.000000           0.000000       0.000000   \n50%              0.000000           0.000000       0.000000   \n75%              0.000000           0.000000       0.000000   \nmax              1.000000           1.000000       1.000000   \n\n       direction.explicit  direction.implicit  \ncount        12768.000000        12768.000000  \nmean             0.126723            0.033443  \nstd              0.332676            0.179797  \nmin              0.000000            0.000000  \n25%              0.000000            0.000000  \n50%              0.000000            0.000000  \n75%              0.000000            0.000000  \nmax              1.000000            1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example_no</th>\n      <th>is_abuse.1</th>\n      <th>is_abuse.0</th>\n      <th>is_abuse.-1</th>\n      <th>is_abuse.-2</th>\n      <th>is_abuse.-3</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n      <th>target.generalised</th>\n      <th>target.individual</th>\n      <th>target.system</th>\n      <th>direction.explicit</th>\n      <th>direction.implicit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6383.500000</td>\n      <td>0.788534</td>\n      <td>0.052553</td>\n      <td>0.063675</td>\n      <td>0.073152</td>\n      <td>0.022086</td>\n      <td>0.001096</td>\n      <td>0.006501</td>\n      <td>0.026159</td>\n      <td>0.002115</td>\n      <td>0.022321</td>\n      <td>0.044643</td>\n      <td>0.000313</td>\n      <td>0.003603</td>\n      <td>0.007597</td>\n      <td>0.149593</td>\n      <td>0.126723</td>\n      <td>0.033443</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3685.948453</td>\n      <td>0.408364</td>\n      <td>0.223149</td>\n      <td>0.244182</td>\n      <td>0.260395</td>\n      <td>0.146971</td>\n      <td>0.033096</td>\n      <td>0.080367</td>\n      <td>0.159615</td>\n      <td>0.045939</td>\n      <td>0.147733</td>\n      <td>0.206527</td>\n      <td>0.017698</td>\n      <td>0.059917</td>\n      <td>0.086833</td>\n      <td>0.356686</td>\n      <td>0.332676</td>\n      <td>0.179797</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3191.750000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6383.500000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9575.250000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>12767.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv(config.input_file('ConvAbuseEMNLPfull.csv'))\n",
    "full_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         violence  directed_vs_generalized      gender        race  \\\ncount  433.000000               433.000000  433.000000  433.000000   \nmean     0.328609                 0.302132    0.221714    0.176598   \nstd      0.376280                 0.359259    0.351597    0.319689   \nmin      0.000000                 0.000000    0.000000    0.000000   \n25%      0.000000                 0.000000    0.000000    0.000000   \n50%      0.166667                 0.166667    0.000000    0.000000   \n75%      0.666667                 0.600000    0.333333    0.200000   \nmax      1.000000                 1.000000    1.000000    1.000000   \n\n       national_origin  disability    religion  sexual_orientation  \ncount       433.000000  433.000000  433.000000          433.000000  \nmean          0.173562    0.118231    0.170243            0.151904  \nstd           0.315602    0.307248    0.339240            0.320386  \nmin           0.000000    0.000000    0.000000            0.000000  \n25%           0.000000    0.000000    0.000000            0.000000  \n50%           0.000000    0.000000    0.000000            0.000000  \n75%           0.200000    0.000000    0.000000            0.000000  \nmax           1.000000    1.000000    1.000000            1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>violence</th>\n      <th>directed_vs_generalized</th>\n      <th>gender</th>\n      <th>race</th>\n      <th>national_origin</th>\n      <th>disability</th>\n      <th>religion</th>\n      <th>sexual_orientation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.328609</td>\n      <td>0.302132</td>\n      <td>0.221714</td>\n      <td>0.176598</td>\n      <td>0.173562</td>\n      <td>0.118231</td>\n      <td>0.170243</td>\n      <td>0.151904</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.376280</td>\n      <td>0.359259</td>\n      <td>0.351597</td>\n      <td>0.319689</td>\n      <td>0.315602</td>\n      <td>0.307248</td>\n      <td>0.339240</td>\n      <td>0.320386</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.166667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.666667</td>\n      <td>0.600000</td>\n      <td>0.333333</td>\n      <td>0.200000</td>\n      <td>0.200000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ethos_df = pd.read_csv(config.input_file('Ethos_Dataset_Multi_Label.csv'), sep=';')\n",
    "full_ethos_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  type.ableism  \\\n32  Please go on. yo muma is so fat when she jumed...             0   \n33  Please go on. no You are being a bit negative....             0   \n62  You are sure? Bite me Can you elaborate on tha...             0   \n82  _ give me head Can you elaborate on that? suck...             0   \n87  Please go on. You look like monkey drool Oh, i...             0   \n\n    type.homophobic  type.intellectual  type.racist  type.sexist  \\\n32                0                  0            0            1   \n33                0                  0            0            1   \n62                0                  0            0            1   \n82                0                  0            0            0   \n87                0                  1            0            0   \n\n    type.sex_harassment  type.transphobic  \n32                    1                 0  \n33                    0                 0  \n62                    0                 0  \n82                    1                 0  \n87                    0                 0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = full_df.drop(columns=['example_no', 'annotator_id', 'conv_id', 'bot', 'target.generalised', 'target.individual', 'target.system', 'direction.explicit', 'direction.implicit', 'is_abuse.1', 'is_abuse.0', 'is_abuse.-1', 'is_abuse.-2', 'is_abuse.-3'])\n",
    "clean_df['text'] = clean_df['prev_agent'] + ' ' + clean_df['prev_user'] + ' ' + clean_df['agent'] + ' ' + clean_df['user']\n",
    "column_order = ['text']\n",
    "column_order.extend(clean_df.columns.drop('text'))\n",
    "clean_df = clean_df[column_order]\n",
    "clean_df = clean_df.drop(columns=['prev_agent', 'prev_user', 'agent', 'user'])\n",
    "\n",
    "label_columns = clean_df.columns.drop('text')\n",
    "clean_df = clean_df[clean_df[label_columns].sum(axis=1) > 0]\n",
    "\n",
    "clean_df.to_csv(config.result_file('clean_df.csv'), index=False)\n",
    "\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  type.ableism  \\\n32  Please go on. yo muma is so fat when she jumed...             0   \n33  Please go on. no You are being a bit negative....             0   \n62  You are sure? Bite me Can you elaborate on tha...             0   \n82  _ give me head Can you elaborate on that? suck...             0   \n87  Please go on. You look like monkey drool Oh, i...             0   \n\n    type.homophobic  type.intellectual  type.racist  type.sexist  \\\n32                0                  0            0            1   \n33                0                  0            0            1   \n62                0                  0            0            1   \n82                0                  0            0            0   \n87                0                  1            0            0   \n\n    type.sex_harassment  type.transphobic                one_hot  \n32                    1                 0  [0, 0, 0, 0, 1, 1, 0]  \n33                    0                 0  [0, 0, 0, 0, 1, 0, 0]  \n62                    0                 0  [0, 0, 0, 0, 1, 0, 0]  \n82                    1                 0  [0, 0, 0, 0, 0, 1, 0]  \n87                    0                 0  [0, 0, 1, 0, 0, 0, 0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n      <th>one_hot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['one_hot'] = clean_df[label_columns].values.tolist()\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "labels = clean_df['one_hot'].values.tolist()\n",
    "text = clean_df['text'].values.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence lenght:  965\n",
      "Avg sentence lenght:  99.05194805194805\n",
      "Std sentence lenght:  76.67330864909947\n",
      "Median sentence lenght:  85.0\n"
     ]
    }
   ],
   "source": [
    "max_sentence_lenght = clean_df['text'].str.len().max()\n",
    "avg_sentence_lenght = clean_df['text'].str.len().mean()\n",
    "std_sentence_lenght = clean_df['text'].str.len().std()\n",
    "median_sentence_lenght = clean_df['text'].str.len().median()\n",
    "print('Max sentence lenght: ', max_sentence_lenght)\n",
    "print('Avg sentence lenght: ', avg_sentence_lenght)\n",
    "print('Std sentence lenght: ', std_sentence_lenght)\n",
    "print('Median sentence lenght: ', median_sentence_lenght)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isnull().values.any()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# reset index of clean_df\n",
    "clean_df = clean_df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# pickle label_columns\n",
    "import pickle\n",
    "with open(config.result_file('label_columns.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_columns, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "max_length = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# create a roberta tokenizer\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "encoded = tokenizer.batch_encode_plus(text, max_length=max_length, truncation=True, padding='max_length')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# tokenize and encode text\n",
    "input_ids = encoded['input_ids']\n",
    "attention_mask = encoded['attention_mask']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train test split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df label indices with only one instance:  [1136, 923, 902, 675, 495, 169]\n"
     ]
    }
   ],
   "source": [
    "# Identifying indices of 'one_hot_labels' entries that only occur once - this will allow us to stratify split our training data later\n",
    "label_counts = clean_df['one_hot'].astype(str).value_counts()\n",
    "one_freq = label_counts[label_counts==1].keys()\n",
    "one_freq_idxs = sorted(list(clean_df[clean_df['one_hot'].astype(str).isin(one_freq)].index), reverse=True)\n",
    "print('df label indices with only one instance: ', one_freq_idxs)\n",
    "\n",
    "# Gathering single instance inputs to force into the training set after stratified split\n",
    "# get the input ids and attention masks for the single instance labels\n",
    "\n",
    "one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n",
    "one_freq_attention_masks = [attention_mask.pop(i) for i in one_freq_idxs]\n",
    "one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "1149"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# create a train, test split of the data (90/10) with uniformly distributed labels\n",
    "test_size = 0.1\n",
    "train_inputs_full, test_inputs, train_labels_full, test_labels = train_test_split(input_ids, labels, random_state=42, test_size=test_size, stratify=labels)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_mask, labels, random_state=42, test_size=test_size, stratify=labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# create a train, validation split of the data (90/10) with uniformly distributed labels\n",
    "val_size = 0.2\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs_full, train_labels_full, random_state=42, test_size=val_size, stratify=train_labels_full)\n",
    "train_masks, val_masks, _, _ = train_test_split(train_masks, train_labels_full, random_state=42, test_size=val_size, stratify=train_labels_full)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Add one frequency data to train data\n",
    "train_inputs.extend(one_freq_input_ids)\n",
    "train_labels.extend(one_freq_labels)\n",
    "train_masks.extend(one_freq_attention_masks)\n",
    "\n",
    "# make to tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/53/pt77f2vn30l8f64lbfm9n54h0000gn/T/ipykernel_73165/141742913.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
      "/var/folders/53/pt77f2vn30l8f64lbfm9n54h0000gn/T/ipykernel_73165/141742913.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = TensorDataset(test_inputs, test_masks, torch.tensor(test_labels))\n",
      "/var/folders/53/pt77f2vn30l8f64lbfm9n54h0000gn/T/ipykernel_73165/141742913.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_data = TensorDataset(val_inputs, val_masks, torch.tensor(val_labels))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# create a TensorDataset with the input ids, attention masks and labels\n",
    "train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
    "# create a DataLoader with the train data\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# create a TensorDataset with the input ids, attention masks and labels\n",
    "test_data = TensorDataset(test_inputs, test_masks, torch.tensor(test_labels))\n",
    "# create a DataLoader with the test data\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "# create a TensorDataset with the input ids, attention masks and labels\n",
    "val_data = TensorDataset(val_inputs, val_masks, torch.tensor(val_labels))\n",
    "# create a DataLoader with the validation data\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "torch.save(train_dataloader, config.result_file('train_dataloader.pt'))\n",
    "torch.save(test_dataloader, config.result_file('test_dataloader.pt'))\n",
    "torch.save(val_dataloader, config.result_file('val_dataloader.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load model and set parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the roberta model and set cuda\n",
    "num_labels = len(labels[0])\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
    "# model.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "]\n",
    "optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from tqdm import trange\n",
    "from torch.nn import BCEWithLogitsLoss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "train_loss_set = []\n",
    "epochs = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4702135810145625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 1/4 [01:26<04:19, 86.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  21.374045801526716\n",
      "Flat Validation Accuracy:  11.594202898550725\n",
      "Train loss: 0.31614773803287083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 2/4 [02:50<02:49, 84.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  65.98465473145781\n",
      "Flat Validation Accuracy:  56.038647342995176\n",
      "Train loss: 0.24473721947934893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 3/4 [04:12<01:23, 83.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  77.88461538461537\n",
      "Flat Validation Accuracy:  68.11594202898551\n",
      "Train loss: 0.20202031400468615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [05:37<00:00, 84.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  85.14412416851441\n",
      "Flat Validation Accuracy:  77.29468599033817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "    # Training\n",
    "\n",
    "    # Set our model to training mode (as opposed to evaluation mode)\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0 #running loss\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    # Train the data for one epoch\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # # Forward pass for multiclass classification\n",
    "        # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # loss = outputs[0]\n",
    "        # logits = outputs[1]\n",
    "\n",
    "        # Forward pass for multilabel classification\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        loss_func = BCEWithLogitsLoss()\n",
    "        loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "        # loss_func = BCELoss()\n",
    "        # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "        train_loss_set.append(loss.item())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "    ###############################################################################\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    # Put model in evaluation mode to evaluate loss on the validation set\n",
    "    model.eval()\n",
    "\n",
    "    # Variables to gather full output\n",
    "    logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "    # Predict\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            b_logit_pred = outs[0]\n",
    "            pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "            b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "            pred_label = pred_label.cpu().numpy()\n",
    "            b_labels = b_labels.cpu().numpy()\n",
    "\n",
    "        tokenized_texts.append(b_input_ids)\n",
    "        logit_preds.append(b_logit_pred)\n",
    "        true_labels.append(b_labels)\n",
    "        pred_labels.append(pred_label)\n",
    "\n",
    "    # Flatten outputs\n",
    "    pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "    true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    threshold = 0.50\n",
    "    pred_bools = [pl>threshold for pl in pred_labels]\n",
    "    true_bools = [tl==1 for tl in true_labels]\n",
    "    val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
    "    val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
    "\n",
    "    print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
    "    print('Flat Validation Accuracy: ', val_flat_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model, config.result_file('roBERTa_MultLabel_class_model.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load(config.result_file('roBERTa_MultLabel_class_model.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# test the model on a single sentence\n",
    "sentence = \"I am a student at the University of Toronto\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# tokenize the sentence\n",
    "tokenized_sentence = tokenizer.tokenize(sentence)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# encode the sentence\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_sentence)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n  )\n)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the model in evaluation mode\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "#track variables\n",
    "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "# Predict\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        b_logit_pred = outs[0]\n",
    "        pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "        pred_label = pred_label.cpu().numpy()\n",
    "        b_labels = b_labels.cpu().numpy()\n",
    "\n",
    "    tokenized_texts.append(b_input_ids)\n",
    "    logit_preds.append(b_logit_pred)\n",
    "    true_labels.append(b_labels)\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "# Flatten outputs\n",
    "tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "true_labels = [item for sublist in true_labels for item in sublist]\n",
    "# Converting flattened binary values to boolean values\n",
    "true_bools = [tl==1 for tl in true_labels]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Accuracy:  0.8196721311475411\n",
      "Test Flat Accuracy:  0.7391304347826086 \n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.00      0.00      0.00         2\n",
      "    type.homophobic       1.00      0.57      0.73         7\n",
      "  type.intellectual       0.85      0.82      0.84        34\n",
      "        type.racist       0.00      0.00      0.00         2\n",
      "        type.sexist       0.84      0.57      0.68        28\n",
      "type.sex_harassment       0.88      0.93      0.90        56\n",
      "   type.transphobic       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.87      0.78      0.82       129\n",
      "          macro avg       0.51      0.41      0.45       129\n",
      "       weighted avg       0.84      0.78      0.80       129\n",
      "        samples avg       0.86      0.82      0.83       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n",
    "\n",
    "# Print and save classification report\n",
    "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
    "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
    "clf_report = classification_report(true_bools,pred_bools,target_names=label_columns)\n",
    "print(clf_report)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'type.ableism', 1: 'type.homophobic', 2: 'type.intellectual', 3: 'type.racist', 4: 'type.sexist', 5: 'type.sex_harassment'}\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "idx2label = dict(zip(range(6),label_columns))\n",
    "print(idx2label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n",
    "true_label_idxs, pred_label_idxs=[],[]\n",
    "for vals in true_bools:\n",
    "    true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
    "for vals in pred_bools:\n",
    "    pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Gathering vectors of label names using idx2label\n",
    "true_label_texts, pred_label_texts = [], []\n",
    "for vals in true_label_idxs:\n",
    "    if vals:\n",
    "        true_label_texts.append([idx2label[val] for val in vals])\n",
    "    else:\n",
    "        true_label_texts.append(vals)\n",
    "\n",
    "for vals in pred_label_idxs:\n",
    "    if vals:\n",
    "        pred_label_texts.append([idx2label[val] for val in vals])\n",
    "    else:\n",
    "        pred_label_texts.append(vals)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Decoding input ids to comment text\n",
    "comment_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        comment_text  \\\n0  Please go on. are you a man or a woman Would y...   \n1  Oh, i like sex. because that is what a blowjob...   \n2  Why do you want my pussy? i wonder about life ...   \n3  You are sure? tell me the time bitch Can you e...   \n4  I have told you before, I do not care about na...   \n\n                          true_labels            pred_labels  \n0                       [type.sexist]          [type.sexist]  \n1               [type.sex_harassment]  [type.sex_harassment]  \n2  [type.sexist, type.sex_harassment]  [type.sex_harassment]  \n3  [type.sexist, type.sex_harassment]          [type.sexist]  \n4                       [type.racist]    [type.intellectual]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>true_labels</th>\n      <th>pred_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Please go on. are you a man or a woman Would y...</td>\n      <td>[type.sexist]</td>\n      <td>[type.sexist]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Oh, i like sex. because that is what a blowjob...</td>\n      <td>[type.sex_harassment]</td>\n      <td>[type.sex_harassment]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do you want my pussy? i wonder about life ...</td>\n      <td>[type.sexist, type.sex_harassment]</td>\n      <td>[type.sex_harassment]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You are sure? tell me the time bitch Can you e...</td>\n      <td>[type.sexist, type.sex_harassment]</td>\n      <td>[type.sexist]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I have told you before, I do not care about na...</td>\n      <td>[type.racist]</td>\n      <td>[type.intellectual]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting lists to df\n",
    "comparisons_df = pd.DataFrame({'comment_text': comment_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n",
    "comparisons_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model in a single class"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import trange\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import RobertaTokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "class ToxicCommentClassifier:\n",
    "    def __init__(self, model, tokenizer, label_columns, threshold=0.50):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.threshold = threshold\n",
    "        self.idx2label = dict(zip(range(len(label_columns)),label_columns))\n",
    "        self.num_labels = len(label_columns)\n",
    "        self.label_columns = label_columns\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'gamma', 'beta']\n",
    "        self.optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01}, {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "                                             ]\n",
    "\n",
    "    def train(self, optimizer, train_dataloader, val_dataloader=None, epochs=4, lr=2e-5, eps=1e-8):\n",
    "        train_loss_set = []\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        optimizer =  optimizer(self.optimizer_grouped_parameters, lr=lr, eps=eps)\n",
    "\n",
    "        # trange is a tqdm wrapper around the normal python range\n",
    "        for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "            # Training\n",
    "\n",
    "            # Set our model to training mode (as opposed to evaluation mode)\n",
    "            self.model.train()\n",
    "\n",
    "            # Tracking variables\n",
    "            tr_loss = 0 #running loss\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "            # Train the data for one epoch\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                # Add batch to GPU\n",
    "                batch = tuple(t.to(self.device) for t in batch)\n",
    "                # Unpack the inputs from our dataloader\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "                # Clear out the gradients (by default they accumulate)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # # Forward pass for multiclass classification\n",
    "                # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "                # loss = outputs[0]\n",
    "                # logits = outputs[1]\n",
    "\n",
    "                # Forward pass for multilabel classification\n",
    "                outputs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "                logits = outputs[0]\n",
    "                loss_func = BCEWithLogitsLoss()\n",
    "                loss = loss_func(logits.view(-1,self.num_labels),b_labels.type_as(logits).view(-1,self.num_labels)) #convert labels to float for calculation\n",
    "                # loss_func = BCELoss()\n",
    "                # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "                train_loss_set.append(loss.item())\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                # Update parameters and take a step using the computed gradient\n",
    "                optimizer.step()\n",
    "                # scheduler.step()\n",
    "                # Update tracking variables\n",
    "                tr_loss += loss.item()\n",
    "                nb_tr_examples += b_input_ids.size(0)\n",
    "                nb_tr_steps += 1\n",
    "\n",
    "            print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "        if val_dataloader:\n",
    "            self.validation(val_dataloader)\n",
    "\n",
    "\n",
    "    def validation(self, val_dataloader):\n",
    "        # Validation\n",
    "\n",
    "        # Put model in evaluation mode to evaluate loss on the validation set\n",
    "        self.model.eval()\n",
    "\n",
    "        # Variables to gather full output\n",
    "        logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "        # Predict\n",
    "        for i, batch in enumerate(val_dataloader):\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            # Unpack the inputs from our dataloader\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            with torch.no_grad():\n",
    "                # Forward pass\n",
    "                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "                b_logit_pred = outs[0]\n",
    "                pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "                pred_label = pred_label.cpu().numpy()\n",
    "                b_labels = b_labels.cpu().numpy()\n",
    "\n",
    "            tokenized_texts.append(b_input_ids)\n",
    "            logit_preds.append(b_logit_pred)\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "\n",
    "        # Flatten outputs\n",
    "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "        true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "        # Calculate Accuracy\n",
    "        threshold = 0.50\n",
    "        pred_bools = [pl>threshold for pl in pred_labels]\n",
    "        true_bools = [tl==1 for tl in true_labels]\n",
    "        val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
    "        val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
    "\n",
    "        print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
    "        print('Flat Validation Accuracy: ', val_flat_accuracy)\n",
    "\n",
    "    def test(self, test_dataloader):\n",
    "        self.model.eval()\n",
    "\n",
    "        #track variables\n",
    "        logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "        # Predict\n",
    "        for i, batch in enumerate(test_dataloader):\n",
    "            batch = tuple(t.to(self.device) for t in batch)\n",
    "            # Unpack the inputs from our dataloader\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            with torch.no_grad():\n",
    "                # Forward pass\n",
    "                outs = self.model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "                b_logit_pred = outs[0]\n",
    "                pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "                b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "                pred_label = pred_label.cpu().numpy()\n",
    "                b_labels = b_labels.cpu().numpy()\n",
    "\n",
    "            tokenized_texts.append(b_input_ids)\n",
    "            logit_preds.append(b_logit_pred)\n",
    "            true_labels.append(b_labels)\n",
    "            pred_labels.append(pred_label)\n",
    "\n",
    "        # Flatten outputs\n",
    "        tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "        pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "        true_labels = [item for sublist in true_labels for item in sublist]\n",
    "        # Converting flattened binary values to boolean values\n",
    "        true_bools = [tl==1 for tl in true_labels]\n",
    "        pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n",
    "\n",
    "        # Print and save classification report\n",
    "        print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
    "        print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
    "        clf_report = classification_report(true_bools,pred_bools,target_names=self.label_columns)\n",
    "        print(clf_report)\n",
    "\n",
    "    def save_modle(self, path, name):\n",
    "        torch.save(self.model, path+name)\n",
    "\n",
    "    def load_model(self, path, name):\n",
    "        self.model = torch.load(path+name)\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # tokenize the sentence\n",
    "        tokenized_sentence = self.tokenizer.tokenize(sentence)\n",
    "        # encode the sentence\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "        # convert to tensor on cpu\n",
    "        tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "        # put the model in evaluation mode\n",
    "        self.model.eval()\n",
    "        # Predict\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            outs = self.model(tokens_tensor, token_type_ids=None, attention_mask=None)\n",
    "            logit_pred = outs[0]\n",
    "            pred_label = torch.sigmoid(logit_pred)\n",
    "            pred_label = pred_label.cpu().numpy()\n",
    "            pred_label = pred_label.flatten().tolist()\n",
    "            pred_label = [pl>self.threshold for pl in pred_label]\n",
    "            pred_label = [self.idx2label[idx] for idx, val in enumerate(pred_label) if val]\n",
    "        return pred_label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model usage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# load the data\n",
    "train_dataloader = torch.load(config.result_file('train_dataloader.pt'))\n",
    "val_dataloader = torch.load(config.result_file('val_dataloader.pt'))\n",
    "test_dataloader = torch.load(config.result_file('test_dataloader.pt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load(config.result_file('roBERTa_MultLabel_class_model.pt'))\n",
    "# roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# load label_columns\n",
    "label_columns = pickle.load(open(config.result_file('label_columns.pkl'),'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# test sentences\n",
    "sentences = [\"I am a student at the University of Toronto\",\n",
    "             \"That bitch stupid af\",\n",
    "             \"I love the islamic culture\",\n",
    "             \"i would not mind to enjoy his physical assets although he doesn't have much else to offer.\",\n",
    "             \"all niggas are ugly\",\n",
    "             \"please dont talk to me, your breath smells very displeasing. brush your teeth!\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# create an instance of the class\n",
    "classifier = ToxicCommentClassifier(model, tokenizer, label_columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a student at the University of Toronto\n",
      "['type.intellectual']\n",
      "\n",
      "That bitch stupid af\n",
      "['type.intellectual']\n",
      "\n",
      "I love the islamic culture\n",
      "['type.intellectual']\n",
      "\n",
      "i would not mind to enjoy his physical assets although he doesn't have much else to offer.\n",
      "['type.sex_harassment']\n",
      "\n",
      "all niggas are ugly\n",
      "['type.intellectual']\n",
      "\n",
      "please dont talk to me, your breath smells very displeasing. brush your teeth!\n",
      "['type.sex_harassment']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    print(classifier.predict(sentence))\n",
    "    print('')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [01:20<00:00, 80.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1501572677106769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  86.66666666666667\n",
      "Flat Validation Accuracy:  79.22705314009661\n"
     ]
    }
   ],
   "source": [
    "# train the classifier\n",
    "optimizer = torch.optim.Adam\n",
    "classifier.train(optimizer, train_dataloader, val_dataloader=val_dataloader, epochs=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Accuracy:  0.8524590163934427\n",
      "Test Flat Accuracy:  0.7913043478260869 \n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.00      0.00      0.00         2\n",
      "    type.homophobic       1.00      0.71      0.83         7\n",
      "  type.intellectual       0.87      0.79      0.83        34\n",
      "        type.racist       0.00      0.00      0.00         2\n",
      "        type.sexist       0.88      0.75      0.81        28\n",
      "type.sex_harassment       0.93      0.91      0.92        56\n",
      "   type.transphobic       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.90      0.81      0.85       129\n",
      "          macro avg       0.52      0.45      0.48       129\n",
      "       weighted avg       0.88      0.81      0.84       129\n",
      "        samples avg       0.87      0.83      0.84       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test the classifier\n",
    "classifier.test(test_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
