{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from config import config\n",
    "from model.toxic_comment_classifier import ToxicCommentClassifier\n",
    "import pickle\n",
    "from transformers import RobertaTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import trange\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         example_no    is_abuse.1    is_abuse.0   is_abuse.-1   is_abuse.-2  \\\ncount  12768.000000  12768.000000  12768.000000  12768.000000  12768.000000   \nmean    6383.500000      0.788534      0.052553      0.063675      0.073152   \nstd     3685.948453      0.408364      0.223149      0.244182      0.260395   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%     3191.750000      1.000000      0.000000      0.000000      0.000000   \n50%     6383.500000      1.000000      0.000000      0.000000      0.000000   \n75%     9575.250000      1.000000      0.000000      0.000000      0.000000   \nmax    12767.000000      1.000000      1.000000      1.000000      1.000000   \n\n        is_abuse.-3  type.ableism  type.homophobic  type.intellectual  \\\ncount  12768.000000  12768.000000     12768.000000       12768.000000   \nmean       0.022086      0.001096         0.006501           0.026159   \nstd        0.146971      0.033096         0.080367           0.159615   \nmin        0.000000      0.000000         0.000000           0.000000   \n25%        0.000000      0.000000         0.000000           0.000000   \n50%        0.000000      0.000000         0.000000           0.000000   \n75%        0.000000      0.000000         0.000000           0.000000   \nmax        1.000000      1.000000         1.000000           1.000000   \n\n        type.racist   type.sexist  type.sex_harassment  type.transphobic  \\\ncount  12768.000000  12768.000000         12768.000000      12768.000000   \nmean       0.002115      0.022321             0.044643          0.000313   \nstd        0.045939      0.147733             0.206527          0.017698   \nmin        0.000000      0.000000             0.000000          0.000000   \n25%        0.000000      0.000000             0.000000          0.000000   \n50%        0.000000      0.000000             0.000000          0.000000   \n75%        0.000000      0.000000             0.000000          0.000000   \nmax        1.000000      1.000000             1.000000          1.000000   \n\n       target.generalised  target.individual  target.system  \\\ncount        12768.000000       12768.000000   12768.000000   \nmean             0.003603           0.007597       0.149593   \nstd              0.059917           0.086833       0.356686   \nmin              0.000000           0.000000       0.000000   \n25%              0.000000           0.000000       0.000000   \n50%              0.000000           0.000000       0.000000   \n75%              0.000000           0.000000       0.000000   \nmax              1.000000           1.000000       1.000000   \n\n       direction.explicit  direction.implicit  \ncount        12768.000000        12768.000000  \nmean             0.126723            0.033443  \nstd              0.332676            0.179797  \nmin              0.000000            0.000000  \n25%              0.000000            0.000000  \n50%              0.000000            0.000000  \n75%              0.000000            0.000000  \nmax              1.000000            1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example_no</th>\n      <th>is_abuse.1</th>\n      <th>is_abuse.0</th>\n      <th>is_abuse.-1</th>\n      <th>is_abuse.-2</th>\n      <th>is_abuse.-3</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n      <th>target.generalised</th>\n      <th>target.individual</th>\n      <th>target.system</th>\n      <th>direction.explicit</th>\n      <th>direction.implicit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6383.500000</td>\n      <td>0.788534</td>\n      <td>0.052553</td>\n      <td>0.063675</td>\n      <td>0.073152</td>\n      <td>0.022086</td>\n      <td>0.001096</td>\n      <td>0.006501</td>\n      <td>0.026159</td>\n      <td>0.002115</td>\n      <td>0.022321</td>\n      <td>0.044643</td>\n      <td>0.000313</td>\n      <td>0.003603</td>\n      <td>0.007597</td>\n      <td>0.149593</td>\n      <td>0.126723</td>\n      <td>0.033443</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3685.948453</td>\n      <td>0.408364</td>\n      <td>0.223149</td>\n      <td>0.244182</td>\n      <td>0.260395</td>\n      <td>0.146971</td>\n      <td>0.033096</td>\n      <td>0.080367</td>\n      <td>0.159615</td>\n      <td>0.045939</td>\n      <td>0.147733</td>\n      <td>0.206527</td>\n      <td>0.017698</td>\n      <td>0.059917</td>\n      <td>0.086833</td>\n      <td>0.356686</td>\n      <td>0.332676</td>\n      <td>0.179797</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3191.750000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6383.500000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9575.250000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>12767.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://github.com/amandacurry/convabuse\n",
    "full_df = pd.read_csv(config.input_file('ConvAbuseEMNLPfull.csv'))\n",
    "full_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   example_no annotator_id                           conv_id  \\\n0           0   Annotator7                          245846.0   \n1           1   Annotator7                          159183.0   \n2           2   Annotator7                          340147.0   \n3           3   Annotator7  95cbaab0f8cb4cb59a3393e7fc61cafe   \n4           4   Annotator7                          270732.0   \n\n                                         prev_agent  \\\n0                  Does that question interest you?   \n1  Does it please you to believe I am a nobe jocky?   \n2                                   Have you tried?   \n3          Will you be travelling in Economy Class?   \n4                                     Please go on.   \n\n                    prev_user                                      agent  \\\n0  because my finger is happy       Why do you say your finger is happy?   \n1                     bye bye                              Please go on.   \n2                        dick                              Please go on.   \n3                         yes         What city will you be flying from?   \n4                      Hello.  How do you do. Please state your problem.   \n\n                              user         bot  is_abuse.1  is_abuse.0  ...  \\\n0              do you rember japan  E.L.I.Z.A.           1           0  ...   \n1              do you like it hard  E.L.I.Z.A.           0           1  ...   \n2  oh what a pickle dear monastery  E.L.I.Z.A.           1           0  ...   \n3                           Sydney   CarbonBot           1           0  ...   \n4                 how old are you?  E.L.I.Z.A.           1           0  ...   \n\n   type.intellectual  type.racist  type.sexist  type.sex_harassment  \\\n0                  0            0            0                    0   \n1                  0            0            0                    0   \n2                  0            0            0                    0   \n3                  0            0            0                    0   \n4                  0            0            0                    0   \n\n   type.transphobic  target.generalised  target.individual  target.system  \\\n0                 0                   0                  0              0   \n1                 0                   0                  0              0   \n2                 0                   0                  0              0   \n3                 0                   0                  0              0   \n4                 0                   0                  0              0   \n\n   direction.explicit  direction.implicit  \n0                   0                   0  \n1                   0                   0  \n2                   0                   0  \n3                   0                   0  \n4                   0                   0  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example_no</th>\n      <th>annotator_id</th>\n      <th>conv_id</th>\n      <th>prev_agent</th>\n      <th>prev_user</th>\n      <th>agent</th>\n      <th>user</th>\n      <th>bot</th>\n      <th>is_abuse.1</th>\n      <th>is_abuse.0</th>\n      <th>...</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n      <th>target.generalised</th>\n      <th>target.individual</th>\n      <th>target.system</th>\n      <th>direction.explicit</th>\n      <th>direction.implicit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Annotator7</td>\n      <td>245846.0</td>\n      <td>Does that question interest you?</td>\n      <td>because my finger is happy</td>\n      <td>Why do you say your finger is happy?</td>\n      <td>do you rember japan</td>\n      <td>E.L.I.Z.A.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Annotator7</td>\n      <td>159183.0</td>\n      <td>Does it please you to believe I am a nobe jocky?</td>\n      <td>bye bye</td>\n      <td>Please go on.</td>\n      <td>do you like it hard</td>\n      <td>E.L.I.Z.A.</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Annotator7</td>\n      <td>340147.0</td>\n      <td>Have you tried?</td>\n      <td>dick</td>\n      <td>Please go on.</td>\n      <td>oh what a pickle dear monastery</td>\n      <td>E.L.I.Z.A.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Annotator7</td>\n      <td>95cbaab0f8cb4cb59a3393e7fc61cafe</td>\n      <td>Will you be travelling in Economy Class?</td>\n      <td>yes</td>\n      <td>What city will you be flying from?</td>\n      <td>Sydney</td>\n      <td>CarbonBot</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Annotator7</td>\n      <td>270732.0</td>\n      <td>Please go on.</td>\n      <td>Hello.</td>\n      <td>How do you do. Please state your problem.</td>\n      <td>how old are you?</td>\n      <td>E.L.I.Z.A.</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  type.ableism  \\\n32  Please go on. yo muma is so fat when she jumed...             0   \n33  Please go on. no You are being a bit negative....             0   \n62  You are sure? Bite me Can you elaborate on tha...             0   \n82  _ give me head Can you elaborate on that? suck...             0   \n87  Please go on. You look like monkey drool Oh, i...             0   \n\n    type.homophobic  type.intellectual  type.racist  type.sexist  \\\n32                0                  0            0            1   \n33                0                  0            0            1   \n62                0                  0            0            1   \n82                0                  0            0            0   \n87                0                  1            0            0   \n\n    type.sex_harassment  type.transphobic  \n32                    1                 0  \n33                    0                 0  \n62                    0                 0  \n82                    1                 0  \n87                    0                 0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = full_df.drop(columns=['example_no', 'annotator_id', 'conv_id', 'bot', 'target.generalised', 'target.individual', 'target.system', 'direction.explicit', 'direction.implicit', 'is_abuse.1', 'is_abuse.0', 'is_abuse.-1', 'is_abuse.-2', 'is_abuse.-3'])\n",
    "clean_df['text'] = clean_df['prev_agent'] + ' ' + clean_df['prev_user'] + ' ' + clean_df['agent'] + ' ' + clean_df['user']\n",
    "column_order = ['text']\n",
    "column_order.extend(clean_df.columns.drop('text'))\n",
    "clean_df = clean_df[column_order]\n",
    "clean_df = clean_df.drop(columns=['prev_agent', 'prev_user', 'agent', 'user'])\n",
    "\n",
    "label_columns = clean_df.columns.drop('text')\n",
    "clean_df = clean_df[clean_df[label_columns].sum(axis=1) > 0]\n",
    "\n",
    "clean_df.to_csv(config.result_file('clean_df.csv'), index=False)\n",
    "\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  type.ableism  \\\n32  Please go on. yo muma is so fat when she jumed...             0   \n33  Please go on. no You are being a bit negative....             0   \n62  You are sure? Bite me Can you elaborate on tha...             0   \n82  _ give me head Can you elaborate on that? suck...             0   \n87  Please go on. You look like monkey drool Oh, i...             0   \n\n    type.homophobic  type.intellectual  type.racist  type.sexist  \\\n32                0                  0            0            1   \n33                0                  0            0            1   \n62                0                  0            0            1   \n82                0                  0            0            0   \n87                0                  1            0            0   \n\n    type.sex_harassment  type.transphobic                one_hot  \n32                    1                 0  [0, 0, 0, 0, 1, 1, 0]  \n33                    0                 0  [0, 0, 0, 0, 1, 0, 0]  \n62                    0                 0  [0, 0, 0, 0, 1, 0, 0]  \n82                    1                 0  [0, 0, 0, 0, 0, 1, 0]  \n87                    0                 0  [0, 0, 1, 0, 0, 0, 0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n      <th>one_hot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['one_hot'] = clean_df[label_columns].values.tolist()\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['type.ableism', 'type.homophobic', 'type.intellectual', 'type.racist',\n",
      "       'type.sexist', 'type.sex_harassment', 'type.transphobic', 'one_hot'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(clean_df.columns.drop('text'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "labels = clean_df['one_hot'].values.tolist()\n",
    "text = clean_df['text'].values.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence lenght:  965\n",
      "Avg sentence lenght:  99.05194805194805\n",
      "Std sentence lenght:  76.67330864909947\n",
      "Median sentence lenght:  85.0\n"
     ]
    }
   ],
   "source": [
    "max_sentence_lenght = clean_df['text'].str.len().max()\n",
    "avg_sentence_lenght = clean_df['text'].str.len().mean()\n",
    "std_sentence_lenght = clean_df['text'].str.len().std()\n",
    "median_sentence_lenght = clean_df['text'].str.len().median()\n",
    "print('Max sentence lenght: ', max_sentence_lenght)\n",
    "print('Avg sentence lenght: ', avg_sentence_lenght)\n",
    "print('Std sentence lenght: ', std_sentence_lenght)\n",
    "print('Median sentence lenght: ', median_sentence_lenght)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isnull().values.any()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "clean_df = clean_df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "with open(config.result_file('label_columns.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_columns, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "max_length = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "encoded = tokenizer.batch_encode_plus(text, max_length=max_length, truncation=True, padding='max_length')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "input_ids = encoded['input_ids']\n",
    "attention_mask = encoded['attention_mask']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train test split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df label indices with only one instance:  [1136, 923, 902, 675, 495, 169]\n"
     ]
    }
   ],
   "source": [
    "label_counts = clean_df['one_hot'].astype(str).value_counts()\n",
    "one_freq = label_counts[label_counts==1].keys()\n",
    "one_freq_idxs = sorted(list(clean_df[clean_df['one_hot'].astype(str).isin(one_freq)].index), reverse=True)\n",
    "print('df label indices with only one instance: ', one_freq_idxs)\n",
    "\n",
    "one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n",
    "one_freq_attention_masks = [attention_mask.pop(i) for i in one_freq_idxs]\n",
    "one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "test_size = 0.1\n",
    "train_inputs_full, test_inputs, train_labels_full, test_labels = train_test_split(input_ids, labels, random_state=42, test_size=test_size, stratify=labels)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_mask, labels, random_state=42, test_size=test_size, stratify=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "val_size = 0.2\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs_full, train_labels_full, random_state=42, test_size=val_size, stratify=train_labels_full)\n",
    "train_masks, val_masks, _, _ = train_test_split(train_masks, train_labels_full, random_state=42, test_size=val_size, stratify=train_labels_full)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "train_inputs.extend(one_freq_input_ids)\n",
    "train_labels.extend(one_freq_labels)\n",
    "train_masks.extend(one_freq_attention_masks)\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\AppData\\Local\\Temp\\ipykernel_11732\\2225995053.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels).to(device))\n",
      "C:\\Users\\Tobias\\AppData\\Local\\Temp\\ipykernel_11732\\2225995053.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = TensorDataset(test_inputs, test_masks, torch.tensor(test_labels).to(device))\n",
      "C:\\Users\\Tobias\\AppData\\Local\\Temp\\ipykernel_11732\\2225995053.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_data = TensorDataset(val_inputs, val_masks, torch.tensor(val_labels).to(device))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, torch.tensor(test_labels))\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(val_inputs, val_masks, torch.tensor(val_labels))\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "torch.save(train_dataloader, config.result_file('train_dataloader.pt'))\n",
    "torch.save(test_dataloader, config.result_file('test_dataloader.pt'))\n",
    "torch.save(val_dataloader, config.result_file('val_dataloader.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load model and set parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n  )\n)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(labels[0])\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "]\n",
    "optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "train_loss_set = []\n",
    "epochs = 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3183755168208369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 1/4 [00:04<00:13,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  66.19047619047619\n",
      "Flat Validation Accuracy:  57.48792270531401\n",
      "Train loss: 0.25315616914519556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 2/4 [00:09<00:09,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  72.72727272727273\n",
      "Flat Validation Accuracy:  61.35265700483091\n",
      "Train loss: 0.1996975811543288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 3/4 [00:13<00:04,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  85.77777777777777\n",
      "Flat Validation Accuracy:  76.81159420289855\n",
      "Train loss: 0.15959514567145594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [00:18<00:00,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  85.84070796460178\n",
      "Flat Validation Accuracy:  76.81159420289855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        loss_func = BCEWithLogitsLoss()\n",
    "        loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels))\n",
    "        train_loss_set.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "    ###############################################################################\n",
    "\n",
    "    model.eval()\n",
    "    logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            b_logit_pred = outs[0]\n",
    "            pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "            b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "            pred_label = pred_label.cpu().numpy()\n",
    "            b_labels = b_labels.cpu().numpy()\n",
    "\n",
    "        tokenized_texts.append(b_input_ids)\n",
    "        logit_preds.append(b_logit_pred)\n",
    "        true_labels.append(b_labels)\n",
    "        pred_labels.append(pred_label)\n",
    "\n",
    "    pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "    true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "    threshold = 0.50\n",
    "    pred_bools = [pl>threshold for pl in pred_labels]\n",
    "    true_bools = [tl==1 for tl in true_labels]\n",
    "    val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
    "    val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
    "\n",
    "    print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
    "    print('Flat Validation Accuracy: ', val_flat_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model, config.result_file('roBERTa_MultLabel_class_model.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "model = torch.load(config.result_file('roBERTa_MultLabel_class_model.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "sentence = \"I am a student at the University of Toronto\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "tokenized_sentence = tokenizer.tokenize(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n  )\n)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        b_logit_pred = outs[0]\n",
    "        pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "        pred_label = pred_label.cpu().numpy()\n",
    "        b_labels = b_labels.cpu().numpy()\n",
    "\n",
    "    tokenized_texts.append(b_input_ids)\n",
    "    logit_preds.append(b_logit_pred)\n",
    "    true_labels.append(b_labels)\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "true_labels = [item for sublist in true_labels for item in sublist]\n",
    "true_bools = [tl==1 for tl in true_labels]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Accuracy:  0.7833333333333333\n",
      "Test Flat Accuracy:  0.7130434782608696 \n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.00      0.00      0.00         2\n",
      "    type.homophobic       1.00      0.29      0.44         7\n",
      "  type.intellectual       0.81      0.76      0.79        34\n",
      "        type.racist       0.00      0.00      0.00         2\n",
      "        type.sexist       1.00      0.50      0.67        28\n",
      "type.sex_harassment       0.83      0.93      0.87        56\n",
      "   type.transphobic       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.85      0.73      0.78       129\n",
      "          macro avg       0.52      0.35      0.40       129\n",
      "       weighted avg       0.84      0.73      0.76       129\n",
      "        samples avg       0.81      0.76      0.78       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_bools = [pl>0.50 for pl in pred_labels]\n",
    "\n",
    "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
    "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
    "clf_report = classification_report(true_bools,pred_bools,target_names=label_columns)\n",
    "print(clf_report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'type.ableism', 1: 'type.homophobic', 2: 'type.intellectual', 3: 'type.racist', 4: 'type.sexist', 5: 'type.sex_harassment'}\n"
     ]
    }
   ],
   "source": [
    "idx2label = dict(zip(range(6),label_columns))\n",
    "print(idx2label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "true_label_idxs, pred_label_idxs=[],[]\n",
    "for vals in true_bools:\n",
    "    true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
    "for vals in pred_bools:\n",
    "    pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "true_label_texts, pred_label_texts = [], []\n",
    "for vals in true_label_idxs:\n",
    "    if vals:\n",
    "        true_label_texts.append([idx2label[val] for val in vals])\n",
    "    else:\n",
    "        true_label_texts.append(vals)\n",
    "\n",
    "for vals in pred_label_idxs:\n",
    "    if vals:\n",
    "        pred_label_texts.append([idx2label[val] for val in vals])\n",
    "    else:\n",
    "        pred_label_texts.append(vals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "comment_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        comment_text  \\\n0  Please go on. are you a man or a woman Would y...   \n1  Oh, i like sex. because that is what a blowjob...   \n2  Why do you want my pussy? i wonder about life ...   \n3  You are sure? tell me the time bitch Can you e...   \n4  I have told you before, I do not care about na...   \n\n                          true_labels                         pred_labels  \n0                       [type.sexist]                                  []  \n1               [type.sex_harassment]               [type.sex_harassment]  \n2  [type.sexist, type.sex_harassment]               [type.sex_harassment]  \n3  [type.sexist, type.sex_harassment]  [type.sexist, type.sex_harassment]  \n4                       [type.racist]                 [type.intellectual]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>true_labels</th>\n      <th>pred_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Please go on. are you a man or a woman Would y...</td>\n      <td>[type.sexist]</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Oh, i like sex. because that is what a blowjob...</td>\n      <td>[type.sex_harassment]</td>\n      <td>[type.sex_harassment]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do you want my pussy? i wonder about life ...</td>\n      <td>[type.sexist, type.sex_harassment]</td>\n      <td>[type.sex_harassment]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You are sure? tell me the time bitch Can you e...</td>\n      <td>[type.sexist, type.sex_harassment]</td>\n      <td>[type.sexist, type.sex_harassment]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I have told you before, I do not care about na...</td>\n      <td>[type.racist]</td>\n      <td>[type.intellectual]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons_df = pd.DataFrame({'comment_text': comment_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n",
    "comparisons_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model usage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "train_dataloader = torch.load(config.result_file('train_dataloader.pt'))\n",
    "val_dataloader = torch.load(config.result_file('val_dataloader.pt'))\n",
    "test_dataloader = torch.load(config.result_file('test_dataloader.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "model = torch.load(config.result_file('roBERTa_MultLabel_class_model.pt'))\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "label_columns = pickle.load(open(config.result_file('label_columns.pkl'),'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "sentences = [\"I am a student at the University of Toronto\",\n",
    "             \"That bitch stupid af\",\n",
    "             \"I love the islamic culture\",\n",
    "             \"i would not mind to enjoy his physical assets although he doesn't have much else to offer.\",\n",
    "             \"all niggas are ugly\",\n",
    "             \"please dont talk to me, your breath smells very displeasing. brush your teeth!\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "classifier = ToxicCommentClassifier(model, tokenizer, label_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a student at the University of Toronto\n",
      "['type.intellectual']\n",
      "\n",
      "That bitch stupid af\n",
      "['type.intellectual']\n",
      "\n",
      "I love the islamic culture\n",
      "[]\n",
      "\n",
      "i would not mind to enjoy his physical assets although he doesn't have much else to offer.\n",
      "['type.sex_harassment']\n",
      "\n",
      "all niggas are ugly\n",
      "['type.intellectual']\n",
      "\n",
      "please dont talk to me, your breath smells very displeasing. brush your teeth!\n",
      "['type.sex_harassment']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    print(classifier.predict(sentence))\n",
    "    print('')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:04<00:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.14864915940496656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  86.47450110864746\n",
      "Flat Validation Accuracy:  78.26086956521739\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "classifier.train(optimizer, train_dataloader, val_dataloader=val_dataloader, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  80.32786885245902\n",
      "Flat Validation Accuracy:  73.04347826086956\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.00      0.00      0.00         2\n",
      "    type.homophobic       1.00      0.57      0.73         7\n",
      "  type.intellectual       0.92      0.68      0.78        34\n",
      "        type.racist       0.00      0.00      0.00         2\n",
      "        type.sexist       0.90      0.64      0.75        28\n",
      "type.sex_harassment       0.80      0.95      0.87        56\n",
      "   type.transphobic       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.85      0.76      0.80       129\n",
      "          macro avg       0.52      0.41      0.45       129\n",
      "       weighted avg       0.84      0.76      0.78       129\n",
      "        samples avg       0.82      0.79      0.79       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classifier.test(test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model on the ETHOS dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "         violence  directed_vs_generalized      gender        race  \\\ncount  433.000000               433.000000  433.000000  433.000000   \nmean     0.328609                 0.302132    0.221714    0.176598   \nstd      0.376280                 0.359259    0.351597    0.319689   \nmin      0.000000                 0.000000    0.000000    0.000000   \n25%      0.000000                 0.000000    0.000000    0.000000   \n50%      0.166667                 0.166667    0.000000    0.000000   \n75%      0.666667                 0.600000    0.333333    0.200000   \nmax      1.000000                 1.000000    1.000000    1.000000   \n\n       national_origin  disability    religion  sexual_orientation  \ncount       433.000000  433.000000  433.000000          433.000000  \nmean          0.173562    0.118231    0.170243            0.151904  \nstd           0.315602    0.307248    0.339240            0.320386  \nmin           0.000000    0.000000    0.000000            0.000000  \n25%           0.000000    0.000000    0.000000            0.000000  \n50%           0.000000    0.000000    0.000000            0.000000  \n75%           0.200000    0.000000    0.000000            0.000000  \nmax           1.000000    1.000000    1.000000            1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>violence</th>\n      <th>directed_vs_generalized</th>\n      <th>gender</th>\n      <th>race</th>\n      <th>national_origin</th>\n      <th>disability</th>\n      <th>religion</th>\n      <th>sexual_orientation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.328609</td>\n      <td>0.302132</td>\n      <td>0.221714</td>\n      <td>0.176598</td>\n      <td>0.173562</td>\n      <td>0.118231</td>\n      <td>0.170243</td>\n      <td>0.151904</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.376280</td>\n      <td>0.359259</td>\n      <td>0.351597</td>\n      <td>0.319689</td>\n      <td>0.315602</td>\n      <td>0.307248</td>\n      <td>0.339240</td>\n      <td>0.320386</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.166667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.666667</td>\n      <td>0.600000</td>\n      <td>0.333333</td>\n      <td>0.200000</td>\n      <td>0.200000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset\n",
    "full_ethos_df = pd.read_csv(config.input_file('Ethos_Dataset_Multi_Label.csv'), sep=';')\n",
    "full_ethos_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "comment                    0\nviolence                   0\ndirected_vs_generalized    0\ngender                     0\nrace                       0\nnational_origin            0\ndisability                 0\nreligion                   0\nsexual_orientation         0\ndtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ethos_df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "comment                    You look like Russian and speak like Indian. B...\nviolence                                                                 1.0\ndirected_vs_generalized                                                  0.5\ngender                                                              0.142857\nrace                                                                0.142857\nnational_origin                                                     0.714286\ndisability                                                               0.0\nreligion                                                                 0.0\nsexual_orientation                                                       0.0\nName: 2, dtype: object"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ethos_df.iloc[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['comment', 'violence', 'directed_vs_generalized', 'gender', 'race',\n       'national_origin', 'disability', 'religion', 'sexual_orientation'],\n      dtype='object')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ethos_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "new_columns = ['text', 'type.ableism', 'type.homophobic', 'type.intellectual', 'type.racist','type.sexist', 'type.sex_harassment', 'type.transphobic']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "mapping = {'comment': 'text', 'gender':'type.sexist', 'race':'type.racist', 'disability':'type.ableism', 'sexual_orientation':'type.homophobic'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "full_ethos_df.rename(columns=mapping, inplace=True)\n",
    "full_ethos_df.drop(columns=[col for col in full_ethos_df.columns if col not in mapping.values()], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "text               You should know women's sports are a joke\ntype.sexist                                              1.0\ntype.racist                                              0.0\ntype.ableism                                             0.0\ntype.homophobic                                          0.0\nName: 0, dtype: object"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ethos_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "for col in new_columns:\n",
    "    if col not in full_ethos_df.columns:\n",
    "        full_ethos_df[col] = 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "text                   You should know women's sports are a joke\ntype.sexist                                                  1.0\ntype.racist                                                  0.0\ntype.ableism                                                 0.0\ntype.homophobic                                              0.0\ntype.intellectual                                            0.0\ntype.sex_harassment                                          0.0\ntype.transphobic                                             0.0\nName: 0, dtype: object"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ethos_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "text                   You should know women's sports are a joke\ntype.ableism                                                 0.0\ntype.homophobic                                              0.0\ntype.intellectual                                            0.0\ntype.racist                                                  0.0\ntype.sexist                                                  1.0\ntype.sex_harassment                                          0.0\ntype.transphobic                                             0.0\nName: 0, dtype: object"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_check = clean_df.columns\n",
    "column_check = [col for col in column_check if 'one_hot' not in col]\n",
    "full_ethos_df = full_ethos_df[column_check]\n",
    "full_ethos_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "for col in full_ethos_df.columns:\n",
    "    if col != 'text':\n",
    "        full_ethos_df[col] = full_ethos_df[col].apply(lambda x: 1.0 if x > threshold else 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "text                   You look like Russian and speak like Indian. B...\ntype.ableism                                                         0.0\ntype.homophobic                                                      0.0\ntype.intellectual                                                    0.0\ntype.racist                                                          0.0\ntype.sexist                                                          0.0\ntype.sex_harassment                                                  0.0\ntype.transphobic                                                     0.0\nName: 2, dtype: object"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first row\n",
    "full_ethos_df.iloc[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def create_dataloader_from_df(df):\n",
    "    df['one_hot'] = df.apply(lambda x: [x[col] for col in label_columns], axis=1)\n",
    "    labels = df['one_hot'].values.tolist()\n",
    "    text = df['text'].values.tolist()\n",
    "    max_length = 100\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    encoded = tokenizer.batch_encode_plus(text, max_length=max_length, truncation=True, padding='max_length')\n",
    "    input_ids = encoded['input_ids']\n",
    "    attention_mask = encoded['attention_mask']\n",
    "\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_mask)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    batch_size = 32\n",
    "    data = TensorDataset(inputs, masks, torch.tensor(labels))\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "    return dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\AppData\\Local\\Temp\\ipykernel_23100\\377985415.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = TensorDataset(inputs, masks, torch.tensor(labels))\n"
     ]
    }
   ],
   "source": [
    "ethos_dataloader = create_dataloader_from_df(full_ethos_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## save the ethos dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "torch.save(ethos_dataloader, config.result_file('ethos_dataloader.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "model = torch.load(config.result_file('roBERTa_MultLabel_class_model.pt'))\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "label_columns = pickle.load(open(config.result_file('label_columns.pkl'),'rb'))\n",
    "\n",
    "classifier = ToxicCommentClassifier(model, tokenizer, label_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  7.420494699646643\n",
      "Flat Validation Accuracy:  14.087759815242496\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.00      0.00      0.00        52\n",
      "    type.homophobic       1.00      0.03      0.06        68\n",
      "  type.intellectual       0.00      0.00      0.00         0\n",
      "        type.racist       0.00      0.00      0.00        71\n",
      "        type.sexist       0.59      0.23      0.33        83\n",
      "type.sex_harassment       0.00      0.00      0.00         0\n",
      "   type.transphobic       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.07      0.08      0.07       274\n",
      "          macro avg       0.23      0.04      0.06       274\n",
      "       weighted avg       0.43      0.08      0.11       274\n",
      "        samples avg       0.04      0.05      0.05       274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "classifier.test(ethos_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# balacing the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  type.ableism  \\\n32  Please go on. yo muma is so fat when she jumed...             0   \n33  Please go on. no You are being a bit negative....             0   \n62  You are sure? Bite me Can you elaborate on tha...             0   \n82  _ give me head Can you elaborate on that? suck...             0   \n87  Please go on. You look like monkey drool Oh, i...             0   \n\n    type.homophobic  type.intellectual  type.racist  type.sexist  \\\n32                0                  0            0            1   \n33                0                  0            0            1   \n62                0                  0            0            1   \n82                0                  0            0            0   \n87                0                  1            0            0   \n\n    type.sex_harassment  type.transphobic  \n32                    1                 0  \n33                    0                 0  \n62                    0                 0  \n82                    1                 0  \n87                    0                 0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "full_df = pd.read_csv(config.input_file('ConvAbuseEMNLPfull.csv'))\n",
    "clean_df = full_df.drop(columns=['example_no', 'annotator_id', 'conv_id', 'bot', 'target.generalised', 'target.individual', 'target.system', 'direction.explicit', 'direction.implicit', 'is_abuse.1', 'is_abuse.0', 'is_abuse.-1', 'is_abuse.-2', 'is_abuse.-3'])\n",
    "clean_df['text'] = clean_df['prev_agent'] + ' ' + clean_df['prev_user'] + ' ' + clean_df['agent'] + ' ' + clean_df['user']\n",
    "column_order = ['text']\n",
    "column_order.extend(clean_df.columns.drop('text'))\n",
    "clean_df = clean_df[column_order]\n",
    "clean_df = clean_df.drop(columns=['prev_agent', 'prev_user', 'agent', 'user'])\n",
    "\n",
    "label_columns = clean_df.columns.drop('text')\n",
    "clean_df = clean_df[clean_df[label_columns].sum(axis=1) > 0]\n",
    "\n",
    "clean_df.to_csv(config.result_file('clean_df.csv'), index=False)\n",
    "\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the label distribution\n",
    "clean_df[label_columns].sum(axis=0).plot(kind='bar')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  type.ableism  \\\n32  Please go on. yo muma is so fat when she jumed...             0   \n33  Please go on. no You are being a bit negative....             0   \n62  You are sure? Bite me Can you elaborate on tha...             0   \n82  _ give me head Can you elaborate on that? suck...             0   \n87  Please go on. You look like monkey drool Oh, i...             0   \n\n    type.homophobic  type.intellectual  type.racist  type.sexist  \\\n32                0                  0            0            1   \n33                0                  0            0            1   \n62                0                  0            0            1   \n82                0                  0            0            0   \n87                0                  1            0            0   \n\n    type.sex_harassment  type.transphobic                one_hot  \n32                    1                 0  [0, 0, 0, 0, 1, 1, 0]  \n33                    0                 0  [0, 0, 0, 0, 1, 0, 0]  \n62                    0                 0  [0, 0, 0, 0, 1, 0, 0]  \n82                    1                 0  [0, 0, 0, 0, 0, 1, 0]  \n87                    0                 0  [0, 0, 1, 0, 0, 0, 0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n      <th>one_hot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a single one hot encoding over all labels\n",
    "clean_df['one_hot'] = clean_df.apply(lambda x: [x[col] for col in label_columns], axis=1)\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# create one hot encoding over all labels\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text                one_hot\n32  Please go on. yo muma is so fat when she jumed...  [0, 0, 0, 0, 1, 1, 0]\n33  Please go on. no You are being a bit negative....  [0, 0, 0, 0, 1, 0, 0]\n62  You are sure? Bite me Can you elaborate on tha...  [0, 0, 0, 0, 1, 0, 0]\n82  _ give me head Can you elaborate on that? suck...  [0, 0, 0, 0, 0, 1, 0]\n87  Please go on. You look like monkey drool Oh, i...  [0, 0, 1, 0, 0, 0, 0]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>one_hot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>[0, 0, 0, 0, 1, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the label columns and keep only the text and the one hot encoding\n",
    "clean_df = clean_df[['text', 'one_hot']]\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the one hot encoding\n",
    "clean_df['one_hot'].value_counts().plot(kind='bar')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  one_hot\n32  Please go on. yo muma is so fat when she jumed...        6\n33  Please go on. no You are being a bit negative....        4\n62  You are sure? Bite me Can you elaborate on tha...        4\n82  _ give me head Can you elaborate on that? suck...        2\n87  Please go on. You look like monkey drool Oh, i...       16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>one_hot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpret the one hot encoding as a binary numbers and assign the corresponding decimal number\n",
    "clean_df['one_hot'] = clean_df['one_hot'].apply(lambda x: int(''.join([str(int(i)) for i in x]), 2))\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# use MultiLabelBinarizer to create a one hot encoding for the labels\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show all the different one hot encodings\n",
    "clean_df['one_hot'].value_counts().plot(kind='bar')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 438), (2, 438), (4, 438), (6, 438), (8, 438), (10, 438), (14, 438), (16, 438), (20, 438), (22, 438), (32, 438), (33, 438), (34, 438), (38, 438), (48, 438), (57, 438), (64, 438), (80, 438), (109, 438)]\n"
     ]
    }
   ],
   "source": [
    "# use over sampling to balance the dataset\n",
    "X = clean_df['text'].values\n",
    "y = clean_df['one_hot'].values\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X.reshape(-1, 1), y)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the new labels\n",
    "pd.Series(y_resampled).value_counts().plot(kind='bar')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  one_hot\n0  Please go on. yo muma is so fat when she jumed...        6\n1  Please go on. no You are being a bit negative....        4\n2  You are sure? Bite me Can you elaborate on tha...        4\n3  _ give me head Can you elaborate on that? suck...        2\n4  Please go on. You look like monkey drool Oh, i...       16",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>one_hot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataframe with the balanced dataset\n",
    "balanced_df = pd.DataFrame({'text': X_resampled.reshape(-1), 'one_hot': y_resampled})\n",
    "balanced_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text                one_hot\n0  Please go on. yo muma is so fat when she jumed...  [0, 0, 0, 0, 1, 1, 0]\n1  Please go on. no You are being a bit negative....  [0, 0, 0, 0, 1, 0, 0]\n2  You are sure? Bite me Can you elaborate on tha...  [0, 0, 0, 0, 1, 0, 0]\n3  _ give me head Can you elaborate on that? suck...  [0, 0, 0, 0, 0, 1, 0]\n4  Please go on. You look like monkey drool Oh, i...  [0, 0, 1, 0, 0, 0, 0]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>one_hot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>[0, 0, 0, 0, 1, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the one hot encoding back to a list of labels\n",
    "balanced_df['one_hot'] = balanced_df['one_hot'].apply(lambda x: [int(i) for i in list('{0:0b}'.format(x).zfill(len(label_columns)))])\n",
    "balanced_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the new labels\n",
    "balanced_df['one_hot'].value_counts().plot(kind='bar')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text                one_hot  \\\n0  Please go on. yo muma is so fat when she jumed...  [0, 0, 0, 0, 1, 1, 0]   \n1  Please go on. no You are being a bit negative....  [0, 0, 0, 0, 1, 0, 0]   \n2  You are sure? Bite me Can you elaborate on tha...  [0, 0, 0, 0, 1, 0, 0]   \n3  _ give me head Can you elaborate on that? suck...  [0, 0, 0, 0, 0, 1, 0]   \n4  Please go on. You look like monkey drool Oh, i...  [0, 0, 1, 0, 0, 0, 0]   \n\n   type.ableism  type.homophobic  type.intellectual  type.racist  type.sexist  \\\n0             0                0                  0            0            1   \n1             0                0                  0            0            1   \n2             0                0                  0            0            1   \n3             0                0                  0            0            0   \n4             0                0                  1            0            0   \n\n   type.sex_harassment  type.transphobic  \n0                    1                 0  \n1                    0                 0  \n2                    0                 0  \n3                    1                 0  \n4                    0                 0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>one_hot</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>[0, 0, 0, 0, 1, 1, 0]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the intial label columns from the one hot encoding\n",
    "balanced_df[label_columns] = pd.DataFrame(balanced_df['one_hot'].values.tolist(), index= balanced_df.index)\n",
    "balanced_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# create train, validation and test set\n",
    "train_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# use the new data to train the model\n",
    "model = torch.load(config.result_file('roBERTa_MultLabel_class_model.pt'))\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "label_columns = pickle.load(open(config.result_file('label_columns.pkl'),'rb'))\n",
    "optimizer = torch.optim.Adam\n",
    "\n",
    "classifier = ToxicCommentClassifier(model, tokenizer, label_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\AppData\\Local\\Temp\\ipykernel_23100\\377985415.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = TensorDataset(inputs, masks, torch.tensor(labels))\n",
      "C:\\Users\\Tobias\\AppData\\Local\\Temp\\ipykernel_23100\\377985415.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = TensorDataset(inputs, masks, torch.tensor(labels))\n",
      "C:\\Users\\Tobias\\AppData\\Local\\Temp\\ipykernel_23100\\377985415.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = TensorDataset(inputs, masks, torch.tensor(labels))\n"
     ]
    }
   ],
   "source": [
    "# create the data loaders\n",
    "train_dataloader = create_dataloader_from_df(train_df)\n",
    "val_dataloader = create_dataloader_from_df(val_df)\n",
    "test_dataloader = create_dataloader_from_df(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 1/3 [00:28<00:57, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.17331753769320643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 2/3 [00:55<00:27, 27.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.07251515826154611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [01:22<00:00, 27.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.05492747281705905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  97.50045612114577\n",
      "Flat Validation Accuracy:  91.96696696696696\n"
     ]
    }
   ],
   "source": [
    "# train the model on the balanced dataset\n",
    "classifier.train(optimizer, train_dataloader, val_dataloader=val_dataloader, epochs=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  97.99678315543207\n",
      "Flat Validation Accuracy:  93.57357357357358\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.97      1.00      0.98       261\n",
      "    type.homophobic       0.98      1.00      0.99       616\n",
      "  type.intellectual       0.99      0.94      0.97       506\n",
      "        type.racist       1.00      1.00      1.00       445\n",
      "        type.sexist       0.94      0.98      0.96       604\n",
      "type.sex_harassment       0.98      0.99      0.98       599\n",
      "   type.transphobic       0.98      1.00      0.99       372\n",
      "\n",
      "          micro avg       0.98      0.98      0.98      3403\n",
      "          macro avg       0.98      0.99      0.98      3403\n",
      "       weighted avg       0.98      0.98      0.98      3403\n",
      "        samples avg       0.98      0.98      0.97      3403\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## Test the model on the test set\n",
    "classifier.test(test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(classifier.model, config.result_file('roBERTa_MultLabel_class_model_balanced.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  36.73469387755102\n",
      "Flat Validation Accuracy:  31.40877598152425\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.75      0.06      0.11        52\n",
      "    type.homophobic       0.76      0.38      0.51        68\n",
      "  type.intellectual       0.00      0.00      0.00         0\n",
      "        type.racist       0.41      0.32      0.36        71\n",
      "        type.sexist       0.54      0.89      0.67        83\n",
      "type.sex_harassment       0.00      0.00      0.00         0\n",
      "   type.transphobic       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.31      0.46      0.37       274\n",
      "          macro avg       0.35      0.24      0.24       274\n",
      "       weighted avg       0.60      0.46      0.44       274\n",
      "        samples avg       0.23      0.29      0.25       274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test the model on the ethos dataset\n",
    "ethos_dataloader = torch.load(config.result_file('ethos_dataloader.pt'))\n",
    "classifier.test(ethos_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}