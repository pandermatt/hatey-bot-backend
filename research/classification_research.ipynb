{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from config import config\n",
    "from model.toxic_comment_classifier import ToxicCommentClassifier\n",
    "import pickle\n",
    "from transformers import RobertaTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import trange\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         example_no    is_abuse.1    is_abuse.0   is_abuse.-1   is_abuse.-2  \\\ncount  12768.000000  12768.000000  12768.000000  12768.000000  12768.000000   \nmean    6383.500000      0.788534      0.052553      0.063675      0.073152   \nstd     3685.948453      0.408364      0.223149      0.244182      0.260395   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%     3191.750000      1.000000      0.000000      0.000000      0.000000   \n50%     6383.500000      1.000000      0.000000      0.000000      0.000000   \n75%     9575.250000      1.000000      0.000000      0.000000      0.000000   \nmax    12767.000000      1.000000      1.000000      1.000000      1.000000   \n\n        is_abuse.-3  type.ableism  type.homophobic  type.intellectual  \\\ncount  12768.000000  12768.000000     12768.000000       12768.000000   \nmean       0.022086      0.001096         0.006501           0.026159   \nstd        0.146971      0.033096         0.080367           0.159615   \nmin        0.000000      0.000000         0.000000           0.000000   \n25%        0.000000      0.000000         0.000000           0.000000   \n50%        0.000000      0.000000         0.000000           0.000000   \n75%        0.000000      0.000000         0.000000           0.000000   \nmax        1.000000      1.000000         1.000000           1.000000   \n\n        type.racist   type.sexist  type.sex_harassment  type.transphobic  \\\ncount  12768.000000  12768.000000         12768.000000      12768.000000   \nmean       0.002115      0.022321             0.044643          0.000313   \nstd        0.045939      0.147733             0.206527          0.017698   \nmin        0.000000      0.000000             0.000000          0.000000   \n25%        0.000000      0.000000             0.000000          0.000000   \n50%        0.000000      0.000000             0.000000          0.000000   \n75%        0.000000      0.000000             0.000000          0.000000   \nmax        1.000000      1.000000             1.000000          1.000000   \n\n       target.generalised  target.individual  target.system  \\\ncount        12768.000000       12768.000000   12768.000000   \nmean             0.003603           0.007597       0.149593   \nstd              0.059917           0.086833       0.356686   \nmin              0.000000           0.000000       0.000000   \n25%              0.000000           0.000000       0.000000   \n50%              0.000000           0.000000       0.000000   \n75%              0.000000           0.000000       0.000000   \nmax              1.000000           1.000000       1.000000   \n\n       direction.explicit  direction.implicit  \ncount        12768.000000        12768.000000  \nmean             0.126723            0.033443  \nstd              0.332676            0.179797  \nmin              0.000000            0.000000  \n25%              0.000000            0.000000  \n50%              0.000000            0.000000  \n75%              0.000000            0.000000  \nmax              1.000000            1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>example_no</th>\n      <th>is_abuse.1</th>\n      <th>is_abuse.0</th>\n      <th>is_abuse.-1</th>\n      <th>is_abuse.-2</th>\n      <th>is_abuse.-3</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n      <th>target.generalised</th>\n      <th>target.individual</th>\n      <th>target.system</th>\n      <th>direction.explicit</th>\n      <th>direction.implicit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n      <td>12768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6383.500000</td>\n      <td>0.788534</td>\n      <td>0.052553</td>\n      <td>0.063675</td>\n      <td>0.073152</td>\n      <td>0.022086</td>\n      <td>0.001096</td>\n      <td>0.006501</td>\n      <td>0.026159</td>\n      <td>0.002115</td>\n      <td>0.022321</td>\n      <td>0.044643</td>\n      <td>0.000313</td>\n      <td>0.003603</td>\n      <td>0.007597</td>\n      <td>0.149593</td>\n      <td>0.126723</td>\n      <td>0.033443</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3685.948453</td>\n      <td>0.408364</td>\n      <td>0.223149</td>\n      <td>0.244182</td>\n      <td>0.260395</td>\n      <td>0.146971</td>\n      <td>0.033096</td>\n      <td>0.080367</td>\n      <td>0.159615</td>\n      <td>0.045939</td>\n      <td>0.147733</td>\n      <td>0.206527</td>\n      <td>0.017698</td>\n      <td>0.059917</td>\n      <td>0.086833</td>\n      <td>0.356686</td>\n      <td>0.332676</td>\n      <td>0.179797</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>3191.750000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>6383.500000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>9575.250000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>12767.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv(config.input_file('ConvAbuseEMNLPfull.csv'))\n",
    "full_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  type.ableism  \\\n32  Please go on. yo muma is so fat when she jumed...             0   \n33  Please go on. no You are being a bit negative....             0   \n62  You are sure? Bite me Can you elaborate on tha...             0   \n82  _ give me head Can you elaborate on that? suck...             0   \n87  Please go on. You look like monkey drool Oh, i...             0   \n\n    type.homophobic  type.intellectual  type.racist  type.sexist  \\\n32                0                  0            0            1   \n33                0                  0            0            1   \n62                0                  0            0            1   \n82                0                  0            0            0   \n87                0                  1            0            0   \n\n    type.sex_harassment  type.transphobic  \n32                    1                 0  \n33                    0                 0  \n62                    0                 0  \n82                    1                 0  \n87                    0                 0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = full_df.drop(columns=['example_no', 'annotator_id', 'conv_id', 'bot', 'target.generalised', 'target.individual', 'target.system', 'direction.explicit', 'direction.implicit', 'is_abuse.1', 'is_abuse.0', 'is_abuse.-1', 'is_abuse.-2', 'is_abuse.-3'])\n",
    "clean_df['text'] = clean_df['prev_agent'] + ' ' + clean_df['prev_user'] + ' ' + clean_df['agent'] + ' ' + clean_df['user']\n",
    "column_order = ['text']\n",
    "column_order.extend(clean_df.columns.drop('text'))\n",
    "clean_df = clean_df[column_order]\n",
    "clean_df = clean_df.drop(columns=['prev_agent', 'prev_user', 'agent', 'user'])\n",
    "\n",
    "label_columns = clean_df.columns.drop('text')\n",
    "clean_df = clean_df[clean_df[label_columns].sum(axis=1) > 0]\n",
    "\n",
    "clean_df.to_csv(config.result_file('clean_df.csv'), index=False)\n",
    "\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  type.ableism  \\\n32  Please go on. yo muma is so fat when she jumed...             0   \n33  Please go on. no You are being a bit negative....             0   \n62  You are sure? Bite me Can you elaborate on tha...             0   \n82  _ give me head Can you elaborate on that? suck...             0   \n87  Please go on. You look like monkey drool Oh, i...             0   \n\n    type.homophobic  type.intellectual  type.racist  type.sexist  \\\n32                0                  0            0            1   \n33                0                  0            0            1   \n62                0                  0            0            1   \n82                0                  0            0            0   \n87                0                  1            0            0   \n\n    type.sex_harassment  type.transphobic                one_hot  \n32                    1                 0  [0, 0, 0, 0, 1, 1, 0]  \n33                    0                 0  [0, 0, 0, 0, 1, 0, 0]  \n62                    0                 0  [0, 0, 0, 0, 1, 0, 0]  \n82                    1                 0  [0, 0, 0, 0, 0, 1, 0]  \n87                    0                 0  [0, 0, 1, 0, 0, 0, 0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>type.ableism</th>\n      <th>type.homophobic</th>\n      <th>type.intellectual</th>\n      <th>type.racist</th>\n      <th>type.sexist</th>\n      <th>type.sex_harassment</th>\n      <th>type.transphobic</th>\n      <th>one_hot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>Please go on. yo muma is so fat when she jumed...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Please go on. no You are being a bit negative....</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>You are sure? Bite me Can you elaborate on tha...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>_ give me head Can you elaborate on that? suck...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0, 0, 0, 0, 0, 1, 0]</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Please go on. You look like monkey drool Oh, i...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['one_hot'] = clean_df[label_columns].values.tolist()\n",
    "clean_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['type.ableism', 'type.homophobic', 'type.intellectual', 'type.racist',\n",
      "       'type.sexist', 'type.sex_harassment', 'type.transphobic', 'one_hot'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print columns without text\n",
    "print(clean_df.columns.drop('text'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "labels = clean_df['one_hot'].values.tolist()\n",
    "text = clean_df['text'].values.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence lenght:  965\n",
      "Avg sentence lenght:  99.05194805194805\n",
      "Std sentence lenght:  76.67330864909947\n",
      "Median sentence lenght:  85.0\n"
     ]
    }
   ],
   "source": [
    "max_sentence_lenght = clean_df['text'].str.len().max()\n",
    "avg_sentence_lenght = clean_df['text'].str.len().mean()\n",
    "std_sentence_lenght = clean_df['text'].str.len().std()\n",
    "median_sentence_lenght = clean_df['text'].str.len().median()\n",
    "print('Max sentence lenght: ', max_sentence_lenght)\n",
    "print('Avg sentence lenght: ', avg_sentence_lenght)\n",
    "print('Std sentence lenght: ', std_sentence_lenght)\n",
    "print('Median sentence lenght: ', median_sentence_lenght)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isnull().values.any()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# reset index of clean_df\n",
    "clean_df = clean_df.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# pickle label_columns\n",
    "with open(config.result_file('label_columns.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_columns, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "max_length = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# create a roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "encoded = tokenizer.batch_encode_plus(text, max_length=max_length, truncation=True, padding='max_length')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# tokenize and encode text\n",
    "input_ids = encoded['input_ids']\n",
    "attention_mask = encoded['attention_mask']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train test split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df label indices with only one instance:  [1136, 923, 902, 675, 495, 169]\n"
     ]
    }
   ],
   "source": [
    "# Identifying indices of 'one_hot_labels' entries that only occur once - this will allow us to stratify split our training data later\n",
    "label_counts = clean_df['one_hot'].astype(str).value_counts()\n",
    "one_freq = label_counts[label_counts==1].keys()\n",
    "one_freq_idxs = sorted(list(clean_df[clean_df['one_hot'].astype(str).isin(one_freq)].index), reverse=True)\n",
    "print('df label indices with only one instance: ', one_freq_idxs)\n",
    "\n",
    "# Gathering single instance inputs to force into the training set after stratified split\n",
    "# get the input ids and attention masks for the single instance labels\n",
    "\n",
    "one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n",
    "one_freq_attention_masks = [attention_mask.pop(i) for i in one_freq_idxs]\n",
    "one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "1149"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# create a train, test split of the data (90/10) with uniformly distributed labels\n",
    "test_size = 0.1\n",
    "train_inputs_full, test_inputs, train_labels_full, test_labels = train_test_split(input_ids, labels, random_state=42, test_size=test_size, stratify=labels)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_mask, labels, random_state=42, test_size=test_size, stratify=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# create a train, validation split of the data (90/10) with uniformly distributed labels\n",
    "val_size = 0.2\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(train_inputs_full, train_labels_full, random_state=42, test_size=val_size, stratify=train_labels_full)\n",
    "train_masks, val_masks, _, _ = train_test_split(train_masks, train_labels_full, random_state=42, test_size=val_size, stratify=train_labels_full)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# Add one frequency data to train data\n",
    "train_inputs.extend(one_freq_input_ids)\n",
    "train_labels.extend(one_freq_labels)\n",
    "train_masks.extend(one_freq_attention_masks)\n",
    "\n",
    "# make to tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/53/pt77f2vn30l8f64lbfm9n54h0000gn/T/ipykernel_14631/141742913.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
      "/var/folders/53/pt77f2vn30l8f64lbfm9n54h0000gn/T/ipykernel_14631/141742913.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = TensorDataset(test_inputs, test_masks, torch.tensor(test_labels))\n",
      "/var/folders/53/pt77f2vn30l8f64lbfm9n54h0000gn/T/ipykernel_14631/141742913.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_data = TensorDataset(val_inputs, val_masks, torch.tensor(val_labels))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# create a TensorDataset with the input ids, attention masks and labels\n",
    "train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
    "# create a DataLoader with the train data\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# create a TensorDataset with the input ids, attention masks and labels\n",
    "test_data = TensorDataset(test_inputs, test_masks, torch.tensor(test_labels))\n",
    "# create a DataLoader with the test data\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "\n",
    "# create a TensorDataset with the input ids, attention masks and labels\n",
    "val_data = TensorDataset(val_inputs, val_masks, torch.tensor(val_labels))\n",
    "# create a DataLoader with the validation data\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "torch.save(train_dataloader, config.result_file('train_dataloader.pt'))\n",
    "torch.save(test_dataloader, config.result_file('test_dataloader.pt'))\n",
    "torch.save(val_dataloader, config.result_file('val_dataloader.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load model and set parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load the roberta model and set cuda\n",
    "num_labels = len(labels[0])\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
    "# model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay_rate': 0.0}\n",
    "]\n",
    "optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=2e-5, eps=1e-8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "train_loss_set = []\n",
    "epochs = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4701829938976853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 1/4 [01:31<04:33, 91.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  0.0\n",
      "Flat Validation Accuracy:  0.0\n",
      "Train loss: 0.3347062512680336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 2/4 [03:03<03:03, 91.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  52.50737463126843\n",
      "Flat Validation Accuracy:  34.78260869565217\n",
      "Train loss: 0.2873256123728222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 3/4 [04:24<01:27, 87.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  77.94117647058823\n",
      "Flat Validation Accuracy:  64.73429951690821\n",
      "Train loss: 0.2082164486249288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 4/4 [05:49<00:00, 87.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  84.94382022471912\n",
      "Flat Validation Accuracy:  76.32850241545893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "\n",
    "    # Training\n",
    "\n",
    "    # Set our model to training mode (as opposed to evaluation mode)\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0 #running loss\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    # Train the data for one epoch\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # # Forward pass for multiclass classification\n",
    "        # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # loss = outputs[0]\n",
    "        # logits = outputs[1]\n",
    "\n",
    "        # Forward pass for multilabel classification\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        logits = outputs[0]\n",
    "        loss_func = BCEWithLogitsLoss()\n",
    "        loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "        # loss_func = BCELoss()\n",
    "        # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
    "        train_loss_set.append(loss.item())\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "    ###############################################################################\n",
    "\n",
    "    # Validation\n",
    "\n",
    "    # Put model in evaluation mode to evaluate loss on the validation set\n",
    "    model.eval()\n",
    "\n",
    "    # Variables to gather full output\n",
    "    logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "    # Predict\n",
    "    for i, batch in enumerate(val_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            b_logit_pred = outs[0]\n",
    "            pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "            b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "            pred_label = pred_label.cpu().numpy()\n",
    "            b_labels = b_labels.cpu().numpy()\n",
    "\n",
    "        tokenized_texts.append(b_input_ids)\n",
    "        logit_preds.append(b_logit_pred)\n",
    "        true_labels.append(b_labels)\n",
    "        pred_labels.append(pred_label)\n",
    "\n",
    "    # Flatten outputs\n",
    "    pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "    true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    threshold = 0.50\n",
    "    pred_bools = [pl>threshold for pl in pred_labels]\n",
    "    true_bools = [tl==1 for tl in true_labels]\n",
    "    val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n",
    "    val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n",
    "\n",
    "    print('F1 Validation Accuracy: ', val_f1_accuracy)\n",
    "    print('Flat Validation Accuracy: ', val_flat_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model, config.result_file('roBERTa_MultLabel_class_model.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load(config.result_file('roBERTa_MultLabel_class_model.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# test the model on a single sentence\n",
    "sentence = \"I am a student at the University of Toronto\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# tokenize the sentence\n",
    "tokenized_sentence = tokenizer.tokenize(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# encode the sentence\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n  )\n)"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put the model in evaluation mode\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "#track variables\n",
    "logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
    "\n",
    "# Predict\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        b_logit_pred = outs[0]\n",
    "        pred_label = torch.sigmoid(b_logit_pred)\n",
    "\n",
    "        b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
    "        pred_label = pred_label.cpu().numpy()\n",
    "        b_labels = b_labels.cpu().numpy()\n",
    "\n",
    "    tokenized_texts.append(b_input_ids)\n",
    "    logit_preds.append(b_logit_pred)\n",
    "    true_labels.append(b_labels)\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "# Flatten outputs\n",
    "tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n",
    "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
    "true_labels = [item for sublist in true_labels for item in sublist]\n",
    "# Converting flattened binary values to boolean values\n",
    "true_bools = [tl==1 for tl in true_labels]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Accuracy:  0.7768595041322314\n",
      "Test Flat Accuracy:  0.7043478260869566 \n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.00      0.00      0.00         2\n",
      "    type.homophobic       1.00      0.43      0.60         7\n",
      "  type.intellectual       0.89      0.74      0.81        34\n",
      "        type.racist       0.00      0.00      0.00         2\n",
      "        type.sexist       0.88      0.50      0.64        28\n",
      "type.sex_harassment       0.79      0.93      0.85        56\n",
      "   type.transphobic       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.83      0.73      0.78       129\n",
      "          macro avg       0.51      0.37      0.41       129\n",
      "       weighted avg       0.82      0.73      0.75       129\n",
      "        samples avg       0.80      0.76      0.77       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n",
    "\n",
    "# Print and save classification report\n",
    "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
    "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
    "clf_report = classification_report(true_bools,pred_bools,target_names=label_columns)\n",
    "print(clf_report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'type.ableism', 1: 'type.homophobic', 2: 'type.intellectual', 3: 'type.racist', 4: 'type.sexist', 5: 'type.sex_harassment'}\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "idx2label = dict(zip(range(6),label_columns))\n",
    "print(idx2label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n",
    "true_label_idxs, pred_label_idxs=[],[]\n",
    "for vals in true_bools:\n",
    "    true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n",
    "for vals in pred_bools:\n",
    "    pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# Gathering vectors of label names using idx2label\n",
    "true_label_texts, pred_label_texts = [], []\n",
    "for vals in true_label_idxs:\n",
    "    if vals:\n",
    "        true_label_texts.append([idx2label[val] for val in vals])\n",
    "    else:\n",
    "        true_label_texts.append(vals)\n",
    "\n",
    "for vals in pred_label_idxs:\n",
    "    if vals:\n",
    "        pred_label_texts.append([idx2label[val] for val in vals])\n",
    "    else:\n",
    "        pred_label_texts.append(vals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# Decoding input ids to comment text\n",
    "comment_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        comment_text  \\\n0  Please go on. are you a man or a woman Would y...   \n1  Oh, i like sex. because that is what a blowjob...   \n2  Why do you want my pussy? i wonder about life ...   \n3  You are sure? tell me the time bitch Can you e...   \n4  I have told you before, I do not care about na...   \n\n                          true_labels                         pred_labels  \n0                       [type.sexist]                       [type.sexist]  \n1               [type.sex_harassment]               [type.sex_harassment]  \n2  [type.sexist, type.sex_harassment]               [type.sex_harassment]  \n3  [type.sexist, type.sex_harassment]  [type.sexist, type.sex_harassment]  \n4                       [type.racist]               [type.sex_harassment]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>true_labels</th>\n      <th>pred_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Please go on. are you a man or a woman Would y...</td>\n      <td>[type.sexist]</td>\n      <td>[type.sexist]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Oh, i like sex. because that is what a blowjob...</td>\n      <td>[type.sex_harassment]</td>\n      <td>[type.sex_harassment]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do you want my pussy? i wonder about life ...</td>\n      <td>[type.sexist, type.sex_harassment]</td>\n      <td>[type.sex_harassment]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You are sure? tell me the time bitch Can you e...</td>\n      <td>[type.sexist, type.sex_harassment]</td>\n      <td>[type.sexist, type.sex_harassment]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I have told you before, I do not care about na...</td>\n      <td>[type.racist]</td>\n      <td>[type.sex_harassment]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting lists to df\n",
    "comparisons_df = pd.DataFrame({'comment_text': comment_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n",
    "comparisons_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model in a single class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model usage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "# load the data\n",
    "train_dataloader = torch.load(config.result_file('train_dataloader.pt'))\n",
    "val_dataloader = torch.load(config.result_file('val_dataloader.pt'))\n",
    "test_dataloader = torch.load(config.result_file('test_dataloader.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load(config.result_file('roBERTa_MultLabel_class_model.pt'))\n",
    "# roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "# load label_columns\n",
    "label_columns = pickle.load(open(config.result_file('label_columns.pkl'),'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# test sentences\n",
    "sentences = [\"I am a student at the University of Toronto\",\n",
    "             \"That bitch stupid af\",\n",
    "             \"I love the islamic culture\",\n",
    "             \"i would not mind to enjoy his physical assets although he doesn't have much else to offer.\",\n",
    "             \"all niggas are ugly\",\n",
    "             \"please dont talk to me, your breath smells very displeasing. brush your teeth!\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# create an instance of the class\n",
    "classifier = ToxicCommentClassifier(model, tokenizer, label_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a student at the University of Toronto\n",
      "[]\n",
      "\n",
      "That bitch stupid af\n",
      "[]\n",
      "\n",
      "I love the islamic culture\n",
      "[]\n",
      "\n",
      "i would not mind to enjoy his physical assets although he doesn't have much else to offer.\n",
      "['type.sex_harassment']\n",
      "\n",
      "all niggas are ugly\n",
      "[]\n",
      "\n",
      "please dont talk to me, your breath smells very displeasing. brush your teeth!\n",
      "['type.sex_harassment']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    print(classifier.predict(sentence))\n",
    "    print('')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [01:19<00:00, 79.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.15453571191540472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  86.68171557562077\n",
      "Flat Validation Accuracy:  78.26086956521739\n"
     ]
    }
   ],
   "source": [
    "# train the classifier\n",
    "optimizer = torch.optim.Adam\n",
    "classifier.train(optimizer, train_dataloader, val_dataloader=val_dataloader, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  86.63967611336034\n",
      "Flat Validation Accuracy:  79.13043478260869\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.00      0.00      0.00         2\n",
      "    type.homophobic       1.00      0.71      0.83         7\n",
      "  type.intellectual       0.91      0.88      0.90        34\n",
      "        type.racist       0.00      0.00      0.00         2\n",
      "        type.sexist       1.00      0.71      0.83        28\n",
      "type.sex_harassment       0.87      0.93      0.90        56\n",
      "   type.transphobic       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.91      0.83      0.87       129\n",
      "          macro avg       0.54      0.46      0.49       129\n",
      "       weighted avg       0.89      0.83      0.85       129\n",
      "        samples avg       0.89      0.86      0.87       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test the classifier\n",
    "classifier.test(test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model on the ETHOS dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "         violence  directed_vs_generalized      gender        race  \\\ncount  433.000000               433.000000  433.000000  433.000000   \nmean     0.328609                 0.302132    0.221714    0.176598   \nstd      0.376280                 0.359259    0.351597    0.319689   \nmin      0.000000                 0.000000    0.000000    0.000000   \n25%      0.000000                 0.000000    0.000000    0.000000   \n50%      0.166667                 0.166667    0.000000    0.000000   \n75%      0.666667                 0.600000    0.333333    0.200000   \nmax      1.000000                 1.000000    1.000000    1.000000   \n\n       national_origin  disability    religion  sexual_orientation  \ncount       433.000000  433.000000  433.000000          433.000000  \nmean          0.173562    0.118231    0.170243            0.151904  \nstd           0.315602    0.307248    0.339240            0.320386  \nmin           0.000000    0.000000    0.000000            0.000000  \n25%           0.000000    0.000000    0.000000            0.000000  \n50%           0.000000    0.000000    0.000000            0.000000  \n75%           0.200000    0.000000    0.000000            0.000000  \nmax           1.000000    1.000000    1.000000            1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>violence</th>\n      <th>directed_vs_generalized</th>\n      <th>gender</th>\n      <th>race</th>\n      <th>national_origin</th>\n      <th>disability</th>\n      <th>religion</th>\n      <th>sexual_orientation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n      <td>433.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.328609</td>\n      <td>0.302132</td>\n      <td>0.221714</td>\n      <td>0.176598</td>\n      <td>0.173562</td>\n      <td>0.118231</td>\n      <td>0.170243</td>\n      <td>0.151904</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.376280</td>\n      <td>0.359259</td>\n      <td>0.351597</td>\n      <td>0.319689</td>\n      <td>0.315602</td>\n      <td>0.307248</td>\n      <td>0.339240</td>\n      <td>0.320386</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.166667</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.666667</td>\n      <td>0.600000</td>\n      <td>0.333333</td>\n      <td>0.200000</td>\n      <td>0.200000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset\n",
    "full_ethos_df = pd.read_csv(config.input_file('Ethos_Dataset_Multi_Label.csv'), sep=';')\n",
    "full_ethos_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "comment                    0\nviolence                   0\ndirected_vs_generalized    0\ngender                     0\nrace                       0\nnational_origin            0\ndisability                 0\nreligion                   0\nsexual_orientation         0\ndtype: int64"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are null values\n",
    "full_ethos_df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "comment                    You look like Russian and speak like Indian. B...\nviolence                                                                 1.0\ndirected_vs_generalized                                                  0.5\ngender                                                              0.142857\nrace                                                                0.142857\nnational_origin                                                     0.714286\ndisability                                                               0.0\nreligion                                                                 0.0\nsexual_orientation                                                       0.0\nName: 2, dtype: object"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ethos_df.iloc[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['comment', 'violence', 'directed_vs_generalized', 'gender', 'race',\n       'national_origin', 'disability', 'religion', 'sexual_orientation'],\n      dtype='object')"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the columns\n",
    "full_ethos_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "new_columns = ['text', 'type.ableism', 'type.homophobic', 'type.intellectual', 'type.racist','type.sexist', 'type.sex_harassment', 'type.transphobic']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# create the mapping from the old columns to the new columns\n",
    "mapping = {'comment': 'text', 'gender':'type.sexist', 'race':'type.racist', 'disability':'type.ableism', 'sexual_orientation':'type.homophobic'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "full_ethos_df.rename(columns=mapping, inplace=True)\n",
    "# drop the columns that are not in mappint.values()\n",
    "full_ethos_df.drop(columns=[col for col in full_ethos_df.columns if col not in mapping.values()], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "text               You should know women's sports are a joke\ntype.sexist                                              1.0\ntype.racist                                              0.0\ntype.ableism                                             0.0\ntype.homophobic                                          0.0\nName: 0, dtype: object"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first row\n",
    "full_ethos_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# check if all column of clean_df are in full_ethos_df, else add them\n",
    "for col in new_columns:\n",
    "    if col not in full_ethos_df.columns:\n",
    "        full_ethos_df[col] = 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "text                   You should know women's sports are a joke\ntype.sexist                                                  1.0\ntype.racist                                                  0.0\ntype.ableism                                                 0.0\ntype.homophobic                                              0.0\ntype.intellectual                                            0.0\ntype.sex_harassment                                          0.0\ntype.transphobic                                             0.0\nName: 0, dtype: object"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first row\n",
    "full_ethos_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "text                   You should know women's sports are a joke\ntype.ableism                                                 0.0\ntype.homophobic                                              0.0\ntype.intellectual                                            0.0\ntype.racist                                                  0.0\ntype.sexist                                                  1.0\ntype.sex_harassment                                          0.0\ntype.transphobic                                             0.0\nName: 0, dtype: object"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order the columns the same way as in clean_df\n",
    "column_check = clean_df.columns\n",
    "# remove one_hot from the columns\n",
    "column_check = [col for col in column_check if 'one_hot' not in col]\n",
    "full_ethos_df = full_ethos_df[column_check]\n",
    "full_ethos_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# for al values in the label columns, the value is set to 1 if the value in the label column is > threshold\n",
    "threshold = 0.5\n",
    "for col in full_ethos_df.columns:\n",
    "    if col != 'text':\n",
    "        full_ethos_df[col] = full_ethos_df[col].apply(lambda x: 1.0 if x > threshold else 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "text                   You look like Russian and speak like Indian. B...\ntype.ableism                                                         0.0\ntype.homophobic                                                      0.0\ntype.intellectual                                                    0.0\ntype.racist                                                          0.0\ntype.sexist                                                          0.0\ntype.sex_harassment                                                  0.0\ntype.transphobic                                                     0.0\nName: 2, dtype: object"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first row\n",
    "full_ethos_df.iloc[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def create_dataloader_from_df(df):\n",
    "    # create a new column 'one_hot' that contains a list of all the labels\n",
    "    df['one_hot'] = df.apply(lambda x: [x[col] for col in label_columns], axis=1)\n",
    "    labels = df['one_hot'].values.tolist()\n",
    "    text = df['text'].values.tolist()\n",
    "    max_length = 100\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    encoded = tokenizer.batch_encode_plus(text, max_length=max_length, truncation=True, padding='max_length')\n",
    "    input_ids = encoded['input_ids']\n",
    "    attention_mask = encoded['attention_mask']\n",
    "\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_mask)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    batch_size = 32\n",
    "    data = TensorDataset(inputs, masks, torch.tensor(labels))\n",
    "    sampler = SequentialSampler(data)\n",
    "    dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "\n",
    "    return dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\AppData\\Local\\Temp\\ipykernel_17720\\1238753810.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = TensorDataset(inputs, masks, torch.tensor(labels))\n"
     ]
    }
   ],
   "source": [
    "# use a dataloader to load the full_ethos_df\n",
    "ethos_dataloader = create_dataloader_from_df(full_ethos_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Test the model on the ETHOS dataset\n",
    "\n",
    "model = torch.load(config.result_file('roBERTa_MultLabel_class_model.pt'))\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "label_columns = pickle.load(open(config.result_file('label_columns.pkl'),'rb'))\n",
    "\n",
    "# create an instance of the class\n",
    "classifier = ToxicCommentClassifier(model, tokenizer, label_columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Validation Accuracy:  7.420494699646643\n",
      "Flat Validation Accuracy:  14.087759815242496\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       type.ableism       0.00      0.00      0.00        52\n",
      "    type.homophobic       1.00      0.03      0.06        68\n",
      "  type.intellectual       0.00      0.00      0.00         0\n",
      "        type.racist       0.00      0.00      0.00        71\n",
      "        type.sexist       0.59      0.23      0.33        83\n",
      "type.sex_harassment       0.00      0.00      0.00         0\n",
      "   type.transphobic       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.07      0.08      0.07       274\n",
      "          macro avg       0.23      0.04      0.06       274\n",
      "       weighted avg       0.43      0.08      0.11       274\n",
      "        samples avg       0.04      0.05      0.05       274\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Tobias\\anaconda3\\envs\\HateyBot\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# test the model on the ethos dataset. calculate the accuracy, precision, recall and f1 score\n",
    "classifier.test(ethos_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}